---
layout: post
title:  "Prueba Kubernetes como en producci칩n"
date:   2025-01-30 16:46:00 +0000
tags: gu칤a, curso, kubernetes, balanceo de carga, kubernetes producci칩n, linux, debian, docker, jenkins, ci, cd, cicd
---

# Pre치mbulo

Este completo tutorial busca crear un entorno con dos m치quinas virtuales, que ejecutan el siguiente software:

1) Docker: para instalar r치pidamente el software a implementar.
2) Jenkins: para automatizar el despliegue a producci칩n.
3) Kubernetes: para crear un balanceo de carga. Depende de los dos primeros.
4) Prometheus: obtiene cientos de puntos de datos sobre la m치quina d칩nde se ejecuta.
5) Grafana: muestra los datos de Prometheus en un historigrama.

# Creaci칩n e instalaci칩n de la VM

En caso de no saber sobre c칩mo crear una m치quina virtual con Debian 12, se recomienda seguir [este tutorial](#) y todas las recomendaciones posteriores que se muestran ah칤, como la comprobaci칩n de los parches de seguridad de la VM, los ajustes sobre el gestor de paquetes, de la fecha y hora del sistema con chronyd, instalar byobu y btop y configurar la IP est치tica (esto permitir치 conectarse v칤a SSH siempre a la misma IP).

## Post-instalaci칩n

Adem치s de lo anteriormente mencionado, se debe instalar:

1. **netcat**: ideal para comprobar si los puertos requeridos por Kubernetes fueron abiertos.

```bash
apt install netcat-traditional -y
```

Docker, por su parte, abrir치 los puertos que requiera, utilizando **iptables**.

2. **iptables-persistent**: permite guardar los puertos editados en iptables, de forma que sean persistentes en el sistema.

```bash
apt install iptables-persistent -y
```

Preguntar치 por el guardado de:
1. Las reglas IPv4: Si
2. Las reglas IPv6: No (com칰nmente, ninguna red interna utiliza IPv6)

3. Se instala **GPG** para la importaci칩n de las claves p칰blicas de nuevos repositorios:

```bash
apt install gpg
```

-------

Luego de tener una 칰nica VM lista, se procede con la instalaci칩n del software. M치s adelante se clonar치 para tener dos m치quinas operativas.

# Iniciar sesi칩n v칤a SSH

En una terminal de Linux, Mac o Windows, se debe tipear:

```bash
ssh sistemas@192.168.0.228 
# Nota: modificar con la IP de la VM d칩nde se est치 trabajando
```

# Elevar permisos

Para ejecutar los siguientes comandos de instalaci칩n, es preciso estar operando como "root":

```bash
su -
# Introducir contrase침a de administrador
```

# Docker 췅 Instalaci칩n

*Esta gu칤a utiliza la [oficial](https://docs.docker.com/engine/install/debian/) de Docker.*

Para correr los contenedores en "pods", un nuevo concepto que incorpora Kubernetes, es necesario tener primero la aplicaci칩n que ejecuta esos contenedores. De los [distintos proyectos que soporta Kubernetes](https://kubernetes.io/docs/setup/production-environment/container-runtimes/), se elije Docker.

Para comenzar con la instalaci칩n, se debe ejecutar la siguiente cadena de comandos, en la terminal de la m치quina virtual:

## A침adir clave oficial GPG de Docker

```bash
apt update && \
apt install ca-certificates curl -y && \
install -m 0755 -d /etc/apt/keyrings && \
curl -fsSL https://download.docker.com/linux/debian/gpg -o /etc/apt/keyrings/docker.asc && \
chmod a+r /etc/apt/keyrings/docker.asc
```

## A침adir el repositorio al gestor apt:

```bash
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/debian \
  $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | \
  tee /etc/apt/sources.list.d/docker.list > /dev/null
```

## Actualizar el repositorio e instalar

```bash
apt update
apt install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin -y
```

## Comprobar la instalaci칩n

El siguiente comando indicar치 que el servicio "docker" est치 corriendo:

```bash
systemctl status docker
```

![mensaje de systemd]({{ base.url}}/assets/img/prueba-kubernetes-como-en-produccion/systemctl-status-docker.png)

# Jenkins 췅 Instalaci칩n

Tomando la gu칤a [oficial](#), se procede a:

## A침adir el GPG de Jenkins:

Estas keys corresponden al la versi칩n LTS de Jenkins.

```bash
wget -O /usr/share/keyrings/jenkins-keyring.asc \
https://pkg.jenkins.io/debian-stable/jenkins.io-2023.key
echo "deb [signed-by=/usr/share/keyrings/jenkins-keyring.asc]" \
https://pkg.jenkins.io/debian-stable binary/ | tee \
/etc/apt/sources.list.d/jenkins.list > /dev/null
```

## Actualizar repositorios con la nueva entrada, e instalar

```bash
apt update
apt install jenkins
```

## Instalar Java

Jenkins utiliza Java para ejecutarse, y la implementaci칩n OpenJDK es ideal, sin necesidad de virar hacia software de c칩digo privativo.

```bash
apt install fontconfig openjdk-17-jre -y
```

## Comprobar la instalaci칩n de Java

```bash
java -version
```

El comando `java -version` deber칤a mostrar en pantalla la siguiente leyenda:

```bash
openjdk version "17.0.13" 2024-10-15
OpenJDK Runtime Environment (build 17.0.13+11-Debian-2deb12u1)
OpenJDK 64-Bit Server VM (build 17.0.13+11-Debian-2deb12u1, mixed mode, sharing)
```

# Kubernetes 췅 Pre-requisitos

## Abrir puertos

Kubernetes requiere conectarse por una serie de puertos, como explica en su [documentaci칩n](https://kubernetes.io/docs/reference/networking/ports-and-protocols/). Esto se configura con **iptables**:

```bash
iptables -A INPUT -p tcp --dport 6443 -j ACCEPT && \
iptables -A INPUT -p tcp --dport 2379 -j ACCEPT && \
iptables -A INPUT -p tcp --dport 2380 -j ACCEPT && \
iptables -A INPUT -p tcp --dport 10250 -j ACCEPT && \
iptables -A INPUT -p tcp --dport 10259 -j ACCEPT && \
iptables -A INPUT -p tcp --dport 10257 -j ACCEPT
```

Luego, se hacen persistentes con:

```bash
netfilter-persistent save
```

Se debe reiniciar el equipo, para confirmar que la apertura de puertos es persistente:

```bash
reboot
```

Al iniciar sesi칩n como usuario "sistemas" y luego elevar privilegios con `su -`, se puede ejecutar:

```bash
iptables -L
```

Los puertos permitidos aparecer치n as칤:

![iptables -L]({{ base.url }}/assets/posts/prueba-kubernetes-como-en-produccion/iptables_-L.png)

# Kubernetes 췅 Instalaci칩n

La web oficial indica en [esta secci칩n](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#installing-runtime):

> Docker Engine does not implement the CRI which is a requirement for a container runtime to work with Kubernetes. For that reason, an additional service cri-dockerd has to be installed. cri-dockerd is a project based on the legacy built-in Docker Engine support that was removed from the kubelet in version 1.24.

El endpoint al que Kubernetes se conectar치 es: *unix:///var/run/cri-dockerd.sock*.

Ahora si, se procede a instalar ***kubeadm*** (bootstrap del cluster), ***kubelet*** (encargado de iniciar pods y contenedores) y ***kubectl*** (la l칤nea de comandos para interactuar con cada cluster).

## A침adir la clave p칰blica para la versi칩n 1.32 de Kubernetes

```bash
curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.32/deb/Release.key | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
``` 

## A침adir el repositorio apt al gestor de paquetes

```bash
echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.32/deb/ /' | tee /etc/apt/sources.list.d/kubernetes.list
```

## Instalar con *apt*

```bash
apt update && \
apt install -y kubelet kubeadm kubectl
```

## Evitar actualizaciones de Kubernetes

```bash
apt-mark hold kubelet kubeadm kubectl
```

Este comando indicar치 por pantalla que no se actualizar치n los paquetes:

```bash
kubelet fijado como retenido.
kubeadm fijado como retenido.
kubectl fijado como retenido.
```

## Habilitar el servicio de *kubelet*

Se debe habilitar con el siguiente comando:

```bash
systemctl enable --now kubelet
```

Al realizar 칠sto, la aplicaci칩n entrar치 en un loop en el cu치l espera a que ***kubeadm*** le indique qu칠 hacer.

# CGroups

游눠 CGroups es un conjunto de funciones del kernel Linux que permite aislar y designar recursos del sistema de forma controlada a cierto proceso. Existen varios drivers para 칠sto.

Docker y Kubernetes deben utilizar el mismo controlador de CGroups. Al utilizar Debian y por ende ***systemd***, ya se utiliza el controlador propio de este init: cgroups v2. Utilizar 칠ste es la forma recomendada, siendo que adem치s ***kubelet*** inicia como un proceso hijo de ***systemd***.

A partir de la versi칩n 1.22, el default es el driver de ***systemd***, por lo cu치l no debe realizarse ning칰n cambio.

[M치s informaci칩n](https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/configure-cgroup-driver/).

## Comprobar la existencia de CGroups V2

Para poder comprobar el tipo de cgroup, se escribe el comando:

```bash
stat -fc %T /sys/fs/cgroup/
```

Que imprimir치 en pantalla: `cgroup2fs`.

# Clonar VM

Si, lleg칩 el momento de clonar la m치quina virtual porque se realizaron las siguientes tareas:

1) Configuraci칩n b치sica del SO.
2) Actualizar el gestor de paquetes.
3) A침adir los repositorios de Docker, Jenkins y Kubernetes.
4) Instalar estos 3 softwares.

Para clonar la m치quina virtual, se apaga ejecutando en la terminal:

```bash
poweroff
```

Luego, en Proxmox se realizan los siguientes clics:

![alt text]({{ base.url }}/assets/posts/prueba-kubernetes-como-en-produccion/clonar-vm-proxmox.png)

La acci칩n "Clone" abrir치 una ventana, d칩nde se completan los campos de la siguiente manera:

- VM ID: 281
- Name: kubernetes-cicd2
- Snapshot: current
- Target storage: Same as source

## Atenci칩n

丘멆잺 Por el momento, se sigue trabajando en la m치quina original.
Se enciende desde la interfaz de Proxmox, y se contin칰a.

# Configuraci칩n 췅 *kubeadm*

***kubeadm*** permitir치 automatizar el despliegue de una aplicaci칩n en un cl칰ster Kubernetes, siendo un "cl칰ster" un conjunto de m치quinas que poseen versiones id칠nticas de ***kubelet***, ***kubeadm*** y ***kubectl*** instalados. Estas m치quinas trabajan en conjunto, para garantizar la alta disponibilidad del software.

Con esta aplicaci칩n es posible crear un cl칰ster viable para producci칩n, es decir, que incluso pueda obtener la [Certificaci칩n de Kubernetes](https://kubernetes.io/blog/2017/10/software-conformance-certification/) (cosa que se har치 hincapi칠 m치s adelante).

## Objetivos

1. Configurar un servidor orquestador.
2. Instalar una red para que los pods puedan comunicarse.

Seguir leyendo en: https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#instructions